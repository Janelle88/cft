r <- raster(ncol=180, nrow=180)
extent(r) <- extent(poly)
rp <- rasterize(poly, r, 'AREA')
# Get some time information
ntime_hist <- grid$ntime_hist
ntime_model <- grid$ntime_model
historical_years <- "1950_2005"
model_years <- "2006_2099"
# Now we can get the historical and model years together
urlbase = "http://thredds.northwestknowledge.net:8080/thredds/dodsC/agg_macav2metdata"
hurls <- c()
murls <- c()
for (model in arg_ref$models){
args = arg_ref$get_args(model)
variables <- arg_ref$variables
params <- args$parameters
scenarios <- args$scenarios
ensemble <- args$ensemble
for (param in params){
for (scenario in scenarios){
hattachment <- paste(c(urlbase, param, model, ensemble, "historical",
historical_years, "CONUS_daily.nc?"), collapse = "_")
mattachment <- paste(c(urlbase, param, model, ensemble, scenario,
model_years, "CONUS_daily.nc?"), collapse = "_")
var <- variables[param]
hquery <- paste0(var, glue("[{0}:{1}:{ntime_hist}][{lat1}:{1}:{lat2}][{lon1}:{1}:{lon2}]"))
mquery <- paste0(var, glue("[{0}:{1}:{ntime_model}][{lat1}:{1}:{lat2}][{lon1}:{1}:{lon2}]"))
hurl <- paste0(hattachment, hquery)
murl <- paste0(mattachment, mquery)
hurls <- append(hurls, hurl)
murls <- append(murls, murl)
}
}
}
# Let's have the historical and modeled urls in pairs
purls <- lapply(1:length(hurls), function(i) c(hurls[i], murls[i]))
# # If we want to parallelize, we could group the pairs further
# `%dopar%` <- foreach::`%dopar%`
# ncores <- parallel::detectCores() - 1
# doParallel::registerDoParallel(ncores)
# purls2 <- split(purls, ceiling(seq_along(purls)/ncores))
# Now the urls are in groups of 7 (on my computer) that may be dl'ed at once
# Let's leave parallelization aside for now, merge and download each pair
pb <- progress_bar$new(total = length(purls))
pb$tick(0)
for (purl in purls){
# Get the local destination file
content <- purl[2]  # 2 for the modeled set, it has more information
query <- basename(content)
cutoff <- regexpr("CONUS", query)[1] - 12  # to get to the scenario
file_name <- paste0(substr(query, 1, cutoff), ".nc") # <--------------------------------- Incorporate the naming convention Imtiaz requested
dst <-file.path(dst_folder, file_name)
if (!file.exists(dst)) {
# Save a local file
ds <- xr$open_mfdataset(purl, concat_dim="time")
# Mask by boundary ...
aoi
# Add location attribute (The park name) ...
# Add time attribute (Daily, 1950 - 2099, historical until 2006, modeled after) ...
ds$to_netcdf(dst)
# Send local file to s3 bucket
creds <- readRDS("~/.aws/credentials.RDS")
Sys.setenv("AWS_ACCESS_KEY_ID" = creds['key'],
"AWS_SECRET_ACCESS_KEY" = creds['skey'],
"AWS_DEFAULT_REGION" = creds['region'])
# Put the file in the bucket
bucket_name <- "cstdata-test"
object <- file.path(location, file_name)
put_folder(location, bucket_name)
put_object(file = dst, object = object, bucket = bucket_name)
}
pb$tick()
}
}
get_park_boundaries <- function(){
# create directory if not present
if (!file.exists('data/shapefiles')) {
dir.create(file.path('data', 'shapefiles'), recursive = TRUE, showWarnings = FALSE)
}
# Download if not already preset
nps_boundary <- "data/shapefiles/nps_boundary.shp"
file <- "data/shapefiles/nps_boundary.zip"
if(!file.exists(nps_boundary)){
url <- "https://irma.nps.gov/DataStore/DownloadFile/627620"
download.file(url = url, destfile = file, method = "curl")  # Check this, not stable yet
unzip(file, exdir = "data/shapefiles")
}
}
# Reference Classes
Grid_Reference <- setRefClass(
"reference_grid",
fields = list(
crs = "character",
extent = "list",
resolution = "numeric",
lats = "numeric",
lons = "numeric",
ntime_hist = "numeric",
ntime_model = "numeric"
),
methods = list(
initialize = function(crs = "+proj=longlat +a=6378137 +f=0.00335281066474748 +pm=0 +no_defs",
extent = list("latmin" = 25.0631, "latmax" = 49.3960,
"lonmin" = -124.7722, "lonmax" = -67.0648),
resolution = 0.04166575,
nlat = 585,
nlon = 1386,
ntime_hist = 20453,
ntime_model = 34332){
crs <<- crs
resolution <<- resolution
extent <<- extent
lats <<- sapply(0:(nlat - 1), function(x) extent["latmin"][[1]] + x*resolution)
lons <<- sapply(0:(nlon - 1), function(x) extent["lonmin"][[1]] + x*resolution)
ntime_hist <<- ntime_hist
ntime_model <<- ntime_model
}
)
)
Argument_Reference <- setRefClass(
"maca_options",
fields = list(
models = "character",
parameters = "character",
scenarios = "character",
variables = "list",
units = "list"),
methods = list(
initialize = function(
models = c("bcc-csm1-1", "bcc-csm1-1-m", "BNU-ESM", "CanESM2", "CCSM4", "CNRM-CM5",
"CSIRO-Mk3-6-0", "GFDL-ESM2M", "GFDL-ESM2G", "HadGEM2-ES365",
"HadGEM2-CC365", "inmcm4", "IPSL-CM5A-LR", "IPSL-CM5A-MR", "IPSL-CM5B-LR",
"MIROC5", "MIROC-ESM", "MIROC-ESM-CHEM", "MRI-CGCM3", "NorESM1-M"),
parameters = c("tasmin", "tasmax", "rhsmin", "rhsmax", "pr", "rsds", "uas", "vas",
"huss", "vpd"),
scenarios = c("rcp45", "rcp85"),
variables = list("tasmin" = "air_temperature",
"tasmax" = "air_temperature",
"rhsmin" = "relative_humidity",
"rhsmax" = "relative_humidity",
"pr" = "precipitation",
"rsds" = "surface_downwelling_shortwave_flux_in_air",
"uas" = "eastward_wind",
"vas" = "northward_wind",
"huss" = "specific_humidity",
"vpd" = "vpd"),
units = list("air_temperature" = "K",
"relative_humidity" = "%",
"precipitation" = "mm",
"surface_downwelling_shortwave_flux_in_air" = "W m-2",
"eastward_wind" = "m s-1",
"northward_wind" = "m s-1",
"specific_humidity" = "kg kg-1",
"vpd" = "kPa")) {
models <<- models
parameters <<- parameters
scenarios <<- scenarios
variables <<- variables
units <<- units
},
get_args = function(model){
args <- list()
for (m in models){
args[[m]] <- list("parameters" = parameters, "scenarios" = scenarios, "ensemble" =  "r1i1p1")
}
# CCSM4 does not have relative humidity and uses ensemble "r6i1p1" (so far the only differences observed)
args[["CCSM4"]]$parameters = c("tasmin", "tasmax", "pr", "rsds", "uas", "vas", "huss", "vpd")
args[["CCSM4"]]$ensemble = "r6i1p1"
return(args[[model]])
},
get_query = function(model, aoi) {
print("Maybe we could build the url queries here?")
}
)
)
library(raster)
install.packages("raster")
library(raster)
reticulate::use_condaenv("dict")
xr <- reticulate::import("xarray")
parkname="Yellowstone National Park"
# Make sure we have the national park shapefile
if (!file.exists("data/shapefiles/nps_boundary.shp")){
get_park_boundaries()
}
# Get the boundaries of the chosen national park
parks <- rgdal::readOGR("data/shapefiles/nps_boundary.shp")
aoi <- parks[grepl(parkname, parks$UNIT_NAME),]
# Make sure we a park-specific destination folder
location <- gsub(" ", "_", tolower(aoi$UNIT_NAME))
print(paste("Retrieving climate data for", location))
dst_folder <- file.path('data', 'netcdfs', location)
if (!dir.exists(dst_folder)) dir.create(dst_folder, recursive = TRUE)
# Instatiate reference objects
grid = Grid_Reference()
arg_ref = Argument_Reference()
# Get the extent coordinates
lonmin <- aoi@bbox[1,1]
lonmax <- aoi@bbox[1,2]
latmin <- aoi@bbox[2,1]
latmax <- aoi@bbox[2,2]
# Now use these from the lat/lons of the full grid to get index positions
lonmindiffs <- abs(grid$lons - lonmin)
lonmaxdiffs <- abs(grid$lons - lonmax)
latmindiffs <- abs(grid$lats - latmin)
latmaxdiffs <- abs(grid$lats - latmax)
lon1 <- match(lonmindiffs[lonmindiffs == min(lonmindiffs)], lonmindiffs)
lon2 <- match(lonmaxdiffs[lonmaxdiffs == min(lonmaxdiffs)], lonmaxdiffs)
lat1 <- match(latmindiffs[latmindiffs == min(latmindiffs)], latmindiffs)
lat2 <- match(latmaxdiffs[latmaxdiffs == min(latmaxdiffs)], latmaxdiffs)
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
grid$resolution
lat2 - lat1
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
aoi_nlat <- ((lat2 - lat1) + 1) / grid$resolution
aoi_nlat
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
aoi_nlat <- ((lat2 - lat1) + 1)
aoi_nlat
lat2
lat1
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
aoi_nlat <- (lat2 - lat1) + 1
aoi_nlon < (lon2 - lon1) + 1
aoi_nlon <- (lon2 - lon1) + 1
aoi_nlon
r <- raster(ncol=aoi_nlon, nrow=aoi_nlat)
r
extent(r) <- extent(aoi)
extent
lon1
x1 <- match(lonmindiffs[lonmindiffs == min(lonmindiffs)], lonmindiffs)
x2 <- match(lonmaxdiffs[lonmaxdiffs == min(lonmaxdiffs)], lonmaxdiffs)
y1 <- match(latmindiffs[latmindiffs == min(latmindiffs)], latmindiffs)
y2 <- match(latmaxdiffs[latmaxdiffs == min(latmaxdiffs)], latmaxdiffs)
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
ny <- (y2 - y1) + 1
nx <- (x2 - x1) + 1
r <- raster(ncol=nx, nrow=ny)
extent(r) <- extent(aoi)
r
grid$cres
grid$crs
proj4(r) <- CRS(grid$crs)
library(proj4)
install.packages(proj4)
?extent
r <- rasterize(aoi, r, 'AREA')
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
ny <- (y2 - y1) + 1
nx <- (x2 - x1) + 1
r <- raster::raster(ncol=nx, nrow=ny)
raster::extent(r) <- raster::extent(aoi)
r <- rasterize(aoi, r, 'AREA')
# Now rasterize shape to get grid locations of boundaries
# Create grid from lat1 to lat2 and lon1 to lon2
ny <- (y2 - y1)
nx <- (x2 - x1)
r <- raster::raster(ncol=nx, nrow=ny)
raster::extent(r) <- raster::extent(aoi)
r <- rasterize(aoi, r, 'AREA')
aoi
grid$crs
r
type(r)
typeof(r)
class(r)
r[[1]]
r[[1,1]]
# Now rasterize shape to get grid locations of boundaries (tricky)
ny <- (y2 - y1) + 1
nx <- (x2 - x1) + 1
r <- raster::raster(ncol=nx, nrow=ny)
r
raster::extent(r) <- raster::extent(aoi)
r
grid$resolution
aoi
r <- rasterize(aoi, r, 'UNIT_CODE')
r <- raster::projectRaster(r, crs = grid$crs)
plot(r)
r
r <- raster::projectRaster(r, crs = grid$crs, res = grid$resolution)
r
# Now rasterize shape to get grid locations of boundaries (tricky)
ny <- (y2 - y1) + 1
nx <- (x2 - x1) + 1
r <- raster::raster(ncol=nx, nrow=ny)
raster::extent(r) <- raster::extent(aoi)
r <- rasterize(aoi, r, 'UNIT_CODE')
r <- raster::projectRaster(r, crs = grid$crs, res = grid$resolution)
r
plot(r)
grid$resolution
glue
glue::glue("[{0}:{1}:{ntime_hist}][{y1}:{1}:{y2}][{x1}:{1}:{x2}]")
glue::glue("[{0}:{1}:{ntime_model}][{y1}:{1}:{y2}][{x1}:{1}:{x2}]")
# Get some time information
ntime_hist <- grid$ntime_hist
ntime_model <- grid$ntime_model
glue::glue("[{0}:{1}:{ntime_model}][{y1}:{1}:{y2}][{x1}:{1}:{x2}]")
coordinates(r)
r
crds = coordinates(r)
length(crds)
r
mask <- r * 0 + 1
plot(mask)
mask
27 * 36
r[r != 1] = NaN
r
mask[mask != 1] = NaN
mask
plot(mask)
xyValues(mask)
raster::xyValues(mask)
p <- rasterToPoints(r, function(x) x == 1)
p
p <- rasterToPoints(mask, function(x) x == 1)
p
length(p)
arry
array
matrix
m = matric(mask)
m = as.matrix(mask)
m
t = m[m == 1]
t
t = m[!is.nan(m)]
t
t[1,1]
t[]
t[1]
typeof(t[1])
t = m[m ! = NA]
t = m[m != NA]
t
t[1]
print(t[1])
class(t[1])
p
plot(p)
p[1]
p[1,1]
length(p)
330 + 310
r
640 * 2
length(p)
points
aoi_pnts <- rasterToPoints(mask, function(x) x == 1)
aoi_pnts
View(aoi_pnts)
ds
purl
# Get some time information
ntime_hist <- grid$ntime_hist
ntime_model <- grid$ntime_model
historical_years <- "1950_2005"
model_years <- "2006_2099"
# Now we can get the historical and model years together
urlbase = "http://thredds.northwestknowledge.net:8080/thredds/dodsC/agg_macav2metdata"
hurls <- c()
murls <- c()
for (model in arg_ref$models){
args = arg_ref$get_args(model)
variables <- arg_ref$variables
params <- args$parameters
scenarios <- args$scenarios
ensemble <- args$ensemble
for (param in params){
for (scenario in scenarios){
hattachment <- paste(c(urlbase, param, model, ensemble, "historical",
historical_years, "CONUS_daily.nc?"), collapse = "_")
mattachment <- paste(c(urlbase, param, model, ensemble, scenario,
model_years, "CONUS_daily.nc?"), collapse = "_")
var <- variables[param]
hquery <- paste0(var, glue::glue("[{0}:{1}:{ntime_hist}][{y1}:{1}:{y2}][{x1}:{1}:{x2}]"))
mquery <- paste0(var, glue::glue("[{0}:{1}:{ntime_model}][{y1}:{1}:{y2}][{x1}:{1}:{x2}]"))
hurl <- paste0(hattachment, hquery)
murl <- paste0(mattachment, mquery)
hurls <- append(hurls, hurl)
murls <- append(murls, murl)
}
}
}
# Let's have the historical and modeled urls in pairs
purls <- lapply(1:length(hurls), function(i) c(hurls[i], murls[i]))
purl = purls[[1]]
purl
# Get the local destination file
content <- purl[2]  # 2 for the modeled set, it has more information
query <- basename(content)
cutoff <- regexpr("CONUS", query)[1] - 12  # to get to the scenario
file_name <- paste0(substr(query, 1, cutoff), ".nc") # <--------------------------------- Incorporate the naming convention Imtiaz requested
dst <-file.path(dst_folder, file_name)
dst
query
content
cutoff <- regexpr("CONUS", query)[1] - 12  # to get to the scenario
cutoff
file_name <- paste0(substr(query, 1, cutoff), ".nc") # <--------------------------------- Incorporate the naming convention Imtiaz requested
file_name
dst <-file.path(dst_folder, file_name)
# Save a local file
ds <- xr$open_mfdataset(purl, concat_dim="time")
ds
ds$lat
ds$coords
mask
raster::match(r, 1)
aoi_pnts <- rasterToPoints(mask, function(x) x == 1)
aoi_pnts
mask[aoi_pnts]
which(mask == 1, arr.ind=TRUE)
raster::which(mask == 1, arr.ind=TRUE)
raster::cellFromXY(mask)
raster::cellFromXY(mask, aoi_points)
raster::cellFromXY(mask, aoi_pnts)
mask[75]
mask[74]
aoi_pnts
aoi_pnts[333,1]
aoi_pnts[333,2]
aoi_ys <- lapply(aoi_pnts, function(x) x[2])
aoi_ys
ys[ys != NA]
aoi_ys[aoi_ys != NA]
ys[:10]
ys[,10]
aoi_ys[,10]
aoi_ys[:10]
raster::cellFromCol(mask, aoi_pnts)
mask
raster::cellFromCol(mask)
raster::cellFromCol(mask,1)
aoi_xs <- raster::cellFromCol(mask, 1) - 1  # I am assuming reticulate maintains 0 indexing
aoi_ys <- raster::cellFromRow(mask, 1) - 1
aoi_xs
aoi_ys
mask
raster::cellFromCol(mask, 1) - 1
aoi_pnts <- rasterToPoints(mask, function(x) x == 1)
aoi_ys <- lapply(aoi_pnts, function(x) x[2])
aoi_ys
aoi_ys[1]
aoi_ys[2]
aoi_ys[50]
aoi_pnts
head(aoi_pnts)
aoi_ys <- lapply(aoi_pnts, function(x) x$y)
length(aoi_pnts)
643 * 3
aoi_pnts <- data.frame(rasterToPoints(mask, function(x) x == 1))
aoi_pnts
head(aoi_pnts)
aoi_ys <- lapply(1:length(aoi_pnts), function(x) x$y)
aoi_ys <- lapply(1:length(aoi_pnts), function(x) x[2])
aoi_ys
aoi_ys <- lapply(1:length(aoi_pnts), function(x) x[[2]])
aoi_ys
aoi_ys <- lapply(aoi_pnts, function(x) x[[2]])
aoi_ys
aoi_ys <- sapply(aoi_pnts, function(x) x[[2]])
aoi_ys
aoi_pnts
ifelse(mask == 1)
match(mask, c(1))
t = match(mask, c(1))
plot(t)
n <- mask %in% 1
n
plot(n)
<- raster(nrow=10, ncol=10)
values(r) <- 1:100
m <- match(r, c(5:10, 50:55))
n <- r %in% c(5:10, 50:55)
r <- raster(nrow=10, ncol=10)
values(r) <- 1:100
m <- match(r, c(5:10, 50:55))
n <- r %in% c(5:10, 50:55)
n
m
plot(m)
# Now rasterize shape to get grid locations of boundaries (check output, move to function)
ny <- (y2 - y1) + 1
nx <- (x2 - x1) + 1
r <- raster::raster(ncol=nx, nrow=ny)
raster::extent(r) <- raster::extent(aoi)
r <- rasterize(aoi, r, 'UNIT_CODE')  # Not generalizable
r <- raster::projectRaster(r, crs = grid$crs, res = grid$resolution)
r
m <- match(r, c(480))
m
plot(m)
ds
r@extent
aoi_extent_pnts <- rasterToPoints(r)
aoi_extent_pnts
r
extent(r)
extent(r)$xmin
extent(r)@xmin
quit()
