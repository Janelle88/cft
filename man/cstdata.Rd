% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cstdata.R
\name{cstdata}
\alias{cstdata}
\title{Climate Scenario Toolkit Data}
\usage{
cstdata(parkname = "Acadia National Park", start_year = 1950,
  end_year = 2099)
}
\arguments{
\item{parkname}{The name of the U.S. National Park for which download data
(character), e.g., "Yellowstone National Park"}

\item{start_year}{The first year of the desired period (integer).}

\item{end_year}{The last year of the desired period (integer).}
}
\description{
Retrieves subsetted data of climate future scenarios for National Parks in
the Contiguous United States. This data is downscaled using the Multivariate
Adaptive Constructed Analogs (MACA) technique.
}
\details{
This package retrieves daily gridded data sets of General Climate Models
(GCM) clipped to specified National Parks. Each of these data sets represent
a single GCM, climate variable and Representative Concentration Pathway (RCP)
from 1950 to 2099. The 1950 to 2005 portion of this time period represents
historical data while the 2006 to 2099 portion represents modeled data. These
can be stored as NetCDF files either locally or on an Amazon Web Service S3
bucket. The original data sets may be found at
\url{ http://thredds.northwestknowledge.net:8080/thredds/reacch_climate_
CMIP5_aggregated_macav2_catalog.html}

Production Notes:

- The use of reticulate may enable us to use Zarr arrays, which are accessible
  directly from an s3 bucket.

- This currently saves everything to disk first, which can be a problem. The
  alternative is to save each file to a tempfile and overwrite. We'll have to
  be careful when parallelizing. However, there has been interest in the
  ability to save locally, and for small parks this is fine, so let's an
  build in an option to save locally and to the s3 bucket.
}
